{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNrGOn97C3FjvNhFF7r1JTz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9rdJmlcmpdP","executionInfo":{"status":"ok","timestamp":1694700155366,"user_tz":-120,"elapsed":41449,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"d524d1f4-5aec-46d5-b490-41753f208d9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'featout_hackathon'...\n","remote: Enumerating objects: 87, done.\u001b[K\n","remote: Counting objects: 100% (87/87), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 87 (delta 38), reused 70 (delta 21), pack-reused 0\u001b[K\n","Receiving objects: 100% (87/87), 23.35 MiB | 27.45 MiB/s, done.\n","Resolving deltas: 100% (38/38), done.\n","/content/featout_hackathon\n","--2023-09-14 14:01:55--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 104.85.240.190, 2600:1409:9800:494::317f, 2600:1409:9800:48e::317f\n","Connecting to download.microsoft.com (download.microsoft.com)|104.85.240.190|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824887076 (787M) [application/octet-stream]\n","Saving to: ‘kagglecatsanddogs_5340.zip’\n","\n","kagglecatsanddogs_5 100%[===================>] 786.67M  57.9MB/s    in 24s     \n","\n","2023-09-14 14:02:20 (32.4 MB/s) - ‘kagglecatsanddogs_5340.zip’ saved [824887076/824887076]\n","\n","Obtaining file:///content/featout_hackathon\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Installing collected packages: featout-exp\n","  Running setup.py develop for featout-exp\n","Successfully installed featout-exp-0.1.0\n"]}],"source":["!git clone https://github.com/MockaWolke/featout_hackathon\n","%cd featout_hackathon\n","!bash load_data.sh\n","!pip install -e ."]},{"cell_type":"code","source":["!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4e-RRNrsfa3","executionInfo":{"status":"ok","timestamp":1694700155732,"user_tz":-120,"elapsed":373,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"ef195afe-5d3f-493b-f419-415f86a4f378"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Already up to date.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn as nn\n","from tqdm import tqdm\n","from featout_exp.utils import CustomDataset, load_model\n","# Reading the dataframe\n","df = pd.read_csv('csvs/second_half.csv', index_col= 0)  # Replace 'your_data_file.csv' with your dataframe's path\n","df\n","dataset = CustomDataset(dataframe=df)\n","\n","# Create DataLoader to handle batching\n","batch_size = 32  # You can modify this as needed\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = load_model(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Training loop\n","num_epochs = 10\n","\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    corrects = 0\n","    total = 0\n","\n","    bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for inputs, labels in bar:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistics\n","        running_loss += loss.item() * inputs.size(0)\n","        corrects += torch.sum(preds == labels.data)\n","        total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = corrects.double() / total\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":895},"id":"UTjfnAicmwDt","executionInfo":{"status":"error","timestamp":1694700694798,"user_tz":-120,"elapsed":539068,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"ce5a6e5f-b548-454b-a277-dafb32500ecc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10: 100%|██████████| 391/391 [01:00<00:00,  6.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Loss: 0.6868 Acc: 0.5469\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 391/391 [00:51<00:00,  7.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10 - Loss: 0.6411 Acc: 0.6299\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 391/391 [00:51<00:00,  7.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10 - Loss: 0.5832 Acc: 0.6909\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 391/391 [00:52<00:00,  7.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10 - Loss: 0.5306 Acc: 0.7353\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 391/391 [00:51<00:00,  7.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10 - Loss: 0.4958 Acc: 0.7617\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10 - Loss: 0.4574 Acc: 0.7819\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 391/391 [00:51<00:00,  7.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10 - Loss: 0.4192 Acc: 0.8061\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 391/391 [00:51<00:00,  7.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10 - Loss: 0.3994 Acc: 0.8164\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10 - Loss: 0.3635 Acc: 0.8378\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 391/391 [00:51<00:00,  7.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10 - Loss: 0.3295 Acc: 0.8560\n","Training complete!\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/391 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3b92a3853480>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Disable gradient calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0"]}]},{"cell_type":"code","source":["test_df = pd.read_csv('csvs/first_half.csv', index_col= 0)\n","test_dataset = CustomDataset(dataframe=test_df)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle= False)\n","\n","\n","model.eval()  # Set the model to evaluation mode\n","\n","all_predictions = []\n","all_true_labels = []\n","all_logits = []\n","loss_per_image = []\n","criterion = nn.CrossEntropyLoss(reduction='none')  # Using 'none' to compute loss for each image\n"],"metadata":{"id":"EUNGhTjrEzqp","executionInfo":{"status":"ok","timestamp":1694701612317,"user_tz":-120,"elapsed":298,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():  # Disable gradient calculation\n","    for inputs, labels in tqdm(test_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Calculate loss for each image in the batch\n","        losses = criterion(outputs, labels)\n","        loss_per_image.extend(losses.cpu().numpy())\n","\n","        # Extract predicted probabilities (logits)\n","        probs = nn.functional.softmax(outputs, dim=1)\n","        all_logits.extend(probs.cpu().numpy())\n","\n","        # Get predicted labels\n","        _, predicted = torch.max(outputs.data, 1)\n","        all_predictions.extend(predicted.cpu().numpy())\n","        all_true_labels.extend(labels.cpu().numpy())\n","\n","# Check the length before assigning\n","assert len(loss_per_image) == len(test_df)\n","assert len(all_predictions) == len(test_df)\n","assert len(all_true_labels) == len(test_df)\n","\n","test_df[\"loss\"] = loss_per_image\n","test_df[\"predicted\"] = all_predictions\n","test_df[\"true_label\"] = all_true_labels\n","test_df[\"logits_cat\"] = [logit[0] for logit in all_logits]  # logits for class \"Cat\"\n","test_df[\"logits_dog\"] = [logit[1] for logit in all_logits]  # logits for class \"Dog\"\n","test_df.to_csv(\"csvs/first_half_worst.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"It3PuMTpEviX","executionInfo":{"status":"ok","timestamp":1694701656741,"user_tz":-120,"elapsed":43886,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"5c25f18f-c4f9-467d-f13f-cff9ed072fb6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 165/391 [00:17<00:22,  9.95it/s]/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n","  warnings.warn(str(msg))\n","100%|██████████| 391/391 [00:43<00:00,  8.95it/s]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","import torch.nn as nn\n","from tqdm import tqdm\n","from featout_exp.utils import CustomDataset, load_model\n","# Reading the dataframe\n","df = pd.read_csv('csvs/first_half.csv', index_col= 0)  # Replace 'your_data_file.csv' with your dataframe's path\n","df\n","dataset = CustomDataset(dataframe=df)\n","\n","# Create DataLoader to handle batching\n","batch_size = 32  # You can modify this as needed\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = load_model(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Training loop\n","num_epochs = 10\n","\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    corrects = 0\n","    total = 0\n","\n","    bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for inputs, labels in bar:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistics\n","        running_loss += loss.item() * inputs.size(0)\n","        corrects += torch.sum(preds == labels.data)\n","        total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = corrects.double() / total\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","\n","print(\"Training complete!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJwRzLAywL4j","executionInfo":{"status":"ok","timestamp":1694702182171,"user_tz":-120,"elapsed":522201,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"a4c9a25f-5749-4e7b-c7bf-128d842a82a2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:  27%|██▋       | 107/391 [00:14<00:34,  8.35it/s]/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n","  warnings.warn(str(msg))\n","Epoch 1/10: 100%|██████████| 391/391 [00:53<00:00,  7.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10 - Loss: 0.6780 Acc: 0.5866\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10 - Loss: 0.6235 Acc: 0.6512\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10: 100%|██████████| 391/391 [00:52<00:00,  7.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10 - Loss: 0.5811 Acc: 0.6924\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10 - Loss: 0.5416 Acc: 0.7262\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10: 100%|██████████| 391/391 [00:51<00:00,  7.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10 - Loss: 0.5091 Acc: 0.7508\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10: 100%|██████████| 391/391 [00:51<00:00,  7.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10 - Loss: 0.4755 Acc: 0.7744\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10: 100%|██████████| 391/391 [00:51<00:00,  7.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10 - Loss: 0.4497 Acc: 0.7909\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10: 100%|██████████| 391/391 [00:52<00:00,  7.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10 - Loss: 0.4143 Acc: 0.8100\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10: 100%|██████████| 391/391 [00:52<00:00,  7.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10 - Loss: 0.3784 Acc: 0.8287\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10: 100%|██████████| 391/391 [00:52<00:00,  7.43it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10 - Loss: 0.3587 Acc: 0.8411\n","Training complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["\n","test_df = pd.read_csv('csvs/second_half.csv', index_col= 0)\n","test_dataset = CustomDataset(dataframe=test_df)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle= False)\n","\n","\n","model.eval()  # Set the model to evaluation mode\n","\n","all_predictions = []\n","all_true_labels = []\n","all_logits = []\n","loss_per_image = []\n","criterion = nn.CrossEntropyLoss(reduction='none')  # Using 'none' to compute loss for each image\n","\n","with torch.no_grad():  # Disable gradient calculation\n","    for inputs, labels in tqdm(test_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Calculate loss for each image in the batch\n","        losses = criterion(outputs, labels)\n","        loss_per_image.extend(losses.cpu().numpy())\n","\n","        # Extract predicted probabilities (logits)\n","        probs = nn.functional.softmax(outputs, dim=1)\n","\n","        all_logits.extend(probs.cpu().numpy())\n","\n","        # Get predicted labels\n","        _, predicted = torch.max(outputs.data, 1)\n","        all_predictions.extend(predicted.cpu().numpy())\n","        all_true_labels.extend(labels.cpu().numpy())\n","\n","# Check the length before assigning\n","assert len(loss_per_image) == len(test_df)\n","assert len(all_predictions) == len(test_df)\n","assert len(all_true_labels) == len(test_df)\n","\n","test_df[\"loss\"] = loss_per_image\n","test_df[\"predicted\"] = all_predictions\n","test_df[\"true_label\"] = all_true_labels\n","test_df[\"logits_cat\"] = [logit[0] for logit in all_logits]  # logits for class \"Cat\"\n","test_df[\"logits_dog\"] = [logit[1] for logit in all_logits]  # logits for class \"Dog\"\n","test_df.to_csv(\"csvs/second_half_worst.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jf7SsMK8FtaB","executionInfo":{"status":"ok","timestamp":1694702357260,"user_tz":-120,"elapsed":41774,"user":{"displayName":"Felix Hammer","userId":"13255875181173490084"}},"outputId":"ca4a01af-cb3e-4fa4-f69e-4c152c3d6c7b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:41<00:00,  9.46it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YHCLmU5tFyjr"},"execution_count":null,"outputs":[]}]}